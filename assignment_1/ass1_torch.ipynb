{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- optimize hyper params (more layers, more neurons, different lr etc, more epochs)\n",
    "- add dropout for regularization (note that we cannot directly then compare training and val loss during training, as dropout is not active during validation)\n",
    "- display the confusion matrix\n",
    "- based on confusion matrix show the numbers that are close to each other, display their spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if possible we want to use the GPU for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into tensors, target should be an integer\n",
    "X = torch.tensor(np.load('x_digits.npy'), dtype=torch.float32)\n",
    "y = torch.tensor(np.load('y_digits.npy'), dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([35631, 129, 71]), torch.Size([35631]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the data and target together\n",
    "zip_data = list(zip(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because the data is ordered (all examples of 0, then all examples of 1, etc.), we need to shuffle it, so our batches contain all classes\n",
    "# we shuffle the pairs of observations and targets and then split the data into training, validation and test sets (64%, 16%, 20%)\n",
    "subsets = torch.utils.data.random_split(zip_data, [0.64, 0.16, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders for the training, validation and test set\n",
    "# in training we want to shuffle the data each epoch, not to overfit to the order of the data\n",
    "train_dataloader = DataLoader(subsets[0], batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(subsets[1], batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(subsets[2], batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define our fully connected neural network\n",
    "# we use batch normalization to stabilize training\n",
    "# we also use it before the first layer to normalize the input data\n",
    "# becaues the spectogram is 2D, we flatten it to a 1D tensor\n",
    "# we use ReLU as activation function\n",
    "# we use kaiming (He) initialization for the weights in linear layers, because we use ReLU\n",
    "class FCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.sequent = nn.Sequential(\n",
    "            nn.BatchNorm1d(129*71), # kinda scaling\n",
    "            nn.Linear(129*71, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "        self.sequent.apply(self.__init_weights)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.sequent(x)\n",
    "        return x\n",
    "    \n",
    "    def __init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.kaiming_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if possible transfer the model to the GPU\n",
    "model = FCNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(subsets[0].indices)\n",
    "n_val = len(subsets[1].indices)\n",
    "n_test = len(subsets[2].indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:04<02:18,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Accuracy: 0.4957 - Loss: 1.4011 - Val Loss: 0.8757, Val accuracy: 0.6951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:08<02:01,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Accuracy: 0.7164 - Loss: 0.8153 - Val Loss: 0.7059, Val accuracy: 0.7616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:12<01:52,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Accuracy: 0.7726 - Loss: 0.6634 - Val Loss: 0.6692, Val accuracy: 0.7765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:16<01:47,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Accuracy: 0.8019 - Loss: 0.5750 - Val Loss: 0.5593, Val accuracy: 0.8167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:20<01:42,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Accuracy: 0.8222 - Loss: 0.5220 - Val Loss: 0.5246, Val accuracy: 0.8260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:25<01:39,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Accuracy: 0.8349 - Loss: 0.4835 - Val Loss: 0.5267, Val accuracy: 0.8276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:30<01:46,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Accuracy: 0.8474 - Loss: 0.4471 - Val Loss: 0.5261, Val accuracy: 0.8244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:35<01:43,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Accuracy: 0.8547 - Loss: 0.4318 - Val Loss: 0.4955, Val accuracy: 0.8379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:40<01:38,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Accuracy: 0.8616 - Loss: 0.4112 - Val Loss: 0.4888, Val accuracy: 0.8413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:44<01:31,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Accuracy: 0.8716 - Loss: 0.3820 - Val Loss: 0.5012, Val accuracy: 0.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:48<01:25,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Accuracy: 0.8730 - Loss: 0.3746 - Val Loss: 0.4878, Val accuracy: 0.8437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:53<01:19,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Accuracy: 0.8787 - Loss: 0.3580 - Val Loss: 0.4815, Val accuracy: 0.8476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:57<01:13,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Accuracy: 0.8827 - Loss: 0.3477 - Val Loss: 0.4685, Val accuracy: 0.8456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [01:02<01:11,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Accuracy: 0.8874 - Loss: 0.3300 - Val Loss: 0.5763, Val accuracy: 0.8232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [01:06<01:06,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Accuracy: 0.8852 - Loss: 0.3341 - Val Loss: 0.4400, Val accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [01:11<01:03,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Accuracy: 0.8934 - Loss: 0.3153 - Val Loss: 0.4327, Val accuracy: 0.8595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [01:17<01:05,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Accuracy: 0.8970 - Loss: 0.3025 - Val Loss: 0.4474, Val accuracy: 0.8570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [01:21<00:57,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Accuracy: 0.8999 - Loss: 0.2970 - Val Loss: 0.4773, Val accuracy: 0.8527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [01:26<00:52,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Accuracy: 0.8968 - Loss: 0.2993 - Val Loss: 0.4673, Val accuracy: 0.8532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [01:31<00:48,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Accuracy: 0.9048 - Loss: 0.2812 - Val Loss: 0.5325, Val accuracy: 0.8362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [01:36<00:43,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Accuracy: 0.9052 - Loss: 0.2801 - Val Loss: 0.4972, Val accuracy: 0.8458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [01:41<00:39,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Accuracy: 0.9055 - Loss: 0.2733 - Val Loss: 0.4953, Val accuracy: 0.8548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [01:46<00:34,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Accuracy: 0.9415 - Loss: 0.1750 - Val Loss: 0.3921, Val accuracy: 0.8820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [01:51<00:30,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Accuracy: 0.9443 - Loss: 0.1665 - Val Loss: 0.4003, Val accuracy: 0.8818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [01:57<00:26,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Accuracy: 0.9431 - Loss: 0.1652 - Val Loss: 0.3890, Val accuracy: 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [02:01<00:19,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Accuracy: 0.9469 - Loss: 0.1588 - Val Loss: 0.4125, Val accuracy: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [02:05<00:14,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 - Accuracy: 0.9482 - Loss: 0.1531 - Val Loss: 0.4473, Val accuracy: 0.8721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [02:10<00:09,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 - Accuracy: 0.9497 - Loss: 0.1528 - Val Loss: 0.4210, Val accuracy: 0.8821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [02:15<00:04,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 - Accuracy: 0.9486 - Loss: 0.1508 - Val Loss: 0.4187, Val accuracy: 0.8830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:19<00:00,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Accuracy: 0.9536 - Loss: 0.1380 - Val Loss: 0.4356, Val accuracy: 0.8760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# we use the AdamW optimizer and reduce the learning rate on plateau after 5 epochs without improvement\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "\n",
    "# we train the model for 30 epochs\n",
    "min_val_loss = float('inf')\n",
    "early_stop = 0\n",
    "\n",
    "for i in tqdm(range(30)):\n",
    "\n",
    "\n",
    "    # we put the model in training mode (important for batch normalization)\n",
    "    model.train()\n",
    "    acc = 0\n",
    "    total_loss = 0\n",
    "    # we do forward and backward pass for each batch until we have seen all training data\n",
    "    # we calculate the accuracy and loss for the training data\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred = model(X_batch)\n",
    "        loss = F.cross_entropy(y_pred, y_batch)\n",
    "        total_loss += loss\n",
    "        acc += (torch.argmax(y_pred, dim=1) == y_batch).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # because we were getting loss and accuracy per batch, we need to average it\n",
    "    acc /= n_train\n",
    "    total_loss /= len(train_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    # for validation we don't need to calculate gradients\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            val_loss += F.cross_entropy(y_pred, y_batch).item()\n",
    "            # we calculate the accuracy for the validation data\n",
    "            # we check the number of cases where the class with highest predicted probability is the same as the target class\n",
    "            # .item() extracts the value from the tensor\n",
    "            val_acc += (torch.argmax(y_pred, dim=1) == y_batch).sum().item()\n",
    "    \n",
    "    val_loss /= len(val_dataloader)\n",
    "\n",
    "    print(f\"Epoch {i+1} - Accuracy: {acc:.4f} - Loss: {total_loss:.4f} - Val Loss: {val_loss:.4f}, Val accuracy: {val_acc/n_val:.4f}\")\n",
    "    # we implement early stopping, if the validation loss doesn't improve for 10 epochs, we stop training\n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        early_stop = 0\n",
    "    else:\n",
    "        early_stop += 1\n",
    "        if early_stop == 10:\n",
    "            break\n",
    "\n",
    "    # we reduce the learning rate if the validation loss doesn't improve for 5 epochs\n",
    "    scheduler.step(val_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8807\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "acc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred = model(X_batch)\n",
    "        acc += (torch.argmax(y_pred, dim=1) == y_batch).sum().item()\n",
    "    \n",
    "acc /= n_test\n",
    "\n",
    "print(f\"Test accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
